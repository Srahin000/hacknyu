# Offline AI Companion - Snapdragon NPU Deployment

Educational AI companion for children that runs 100% offline using Snapdragon NPU acceleration.

## ðŸŽ‰ NEW: Complete Voice Assistant!

**Harry Potter Voice Assistant** - Full voice-to-voice conversation pipeline:
- Wake word detection â†’ Speech recognition â†’ AI response â†’ Voice output
- Run it now: `python harry_voice_assistant.py --test`
- Full guide: [VOICE_ASSISTANT_GUIDE.md](VOICE_ASSISTANT_GUIDE.md)

## Features

- **Voice Assistant** - Complete voice-to-voice AI conversation
- Speech-to-Text (Whisper) on NPU (~44ms latency)
- Emotion Recognition (Wav2Vec2) on NPU (97.46% accuracy)
- Text-to-Speech with pyttsx3 (offline)
- Custom wake word detection ("Harry Potter")
- LLM responses with Llama 3.2 (CPU-optimized)
- Real-time Unity avatar integration
- Local storage with Snowflake sync

## Quick Start

### ðŸŽ¤ Voice Assistant (Ready Now!)

```powershell
# 1. Check system readiness
python check_voice_assistant_ready.py

# 2. Run in test mode (recommended first time)
python harry_voice_assistant.py --test

# 3. Run with wake word
python harry_voice_assistant.py

# Or use the launcher
start_harry_voice.bat
```

See [VOICE_ASSISTANT_GUIDE.md](VOICE_ASSISTANT_GUIDE.md) for complete setup!

### ðŸš€ NPU Deployment (Advanced)

#### Prerequisites

- Python 3.10 (required for some TTS options)
- Qualcomm AI Hub API Key ([get one here](https://app.aihub.qualcomm.com/))
- Snapdragon NPU-enabled device (e.g., Samsung Galaxy S24)

#### Installation

```powershell
# Create Python 3.10 environment
conda create -n hacknyu_offline python=3.10 -y
conda activate hacknyu_offline

# Install dependencies
pip install -r requirements.txt

# Set up API key in .env file
QAI_HUB_API_KEY=your_api_key_here
TARGET_DEVICE=Samsung Galaxy S24
```

### Deploy Models

```powershell
# 1. Convert emotion model
python convert_emotion_model.py

# 2. Deploy to NPU (takes 10-30 min)
python deploy_fixed.py --model models/emotion_wav2vec2/model.onnx

# 3. Test everything
python test_emotion_inference.py
python check_device.py
```

## Project Structure

```
HackNYU/
â”œâ”€â”€ deploy_fixed.py          # Model deployment (corrected SDK API)
â”œâ”€â”€ deploy.py                # Original deployment script
â”œâ”€â”€ config.py                # Configuration
â”œâ”€â”€ convert_emotion_model.py # Convert Wav2Vec2 to ONNX
â”œâ”€â”€ check_device.py          # Verify device connection
â”œâ”€â”€ test_emotion_inference.py # Test emotion model
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env                     # API keys (create this)
â”œâ”€â”€ models/                  # ONNX models
â”œâ”€â”€ deployed_models/         # Compiled NPU models
â””â”€â”€ ppn_files/              # Picovoice wake word files
```

## Documentation

See **[GUIDE.md](GUIDE.md)** for complete documentation including:
- Detailed setup instructions
- Model deployment workflow
- NPU compilation guide
- Performance optimization
- Troubleshooting
- Full system architecture

## Performance

| Component | Device | Latency | Offline |
|-----------|--------|---------|---------|
| Wake Word | NPU | <50ms | âœ… |
| STT (Whisper) | NPU | ~44ms | âœ… |
| Emotion (Wav2Vec2) | NPU | ~80ms | âœ… |
| TTS (Picovoice Orca) | CPU | ~500ms | âœ… |
| **Total Pipeline** | Mixed | **<1s** | **âœ…** |

## Support

- **Qualcomm AI Hub**: [Documentation](https://app.aihub.qualcomm.com/docs/index.html)
- **Full Guide**: See [GUIDE.md](GUIDE.md)
- **Issues**: Check troubleshooting section in GUIDE.md

## License

Educational and development purposes. See individual model licenses for commercial use.
